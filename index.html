<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Guangzhao (Alex) He</title>

    <meta name="author" content="Guangzhao He">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="shortcut icon" href="images/icon.png" type="image/x-icon">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <style>
      /* Define a class for rounded corners */
      .rounded {
        border-radius: 15px; /* Adjust the border radius as needed */
        overflow: hidden; /* Ensure content within rounded corners is clipped */
      }
    </style>

  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Guangzhao (Alex) He
                </p>
                <p>
                  I'm a senior undergraduate majoring in Computer Science at <a href="http://ckc.zju.edu.cn/ckcen/">Chu Kochen Honors College</a>, <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>. I currently hold a GPA of 3.99/4.0 and expect to receive my degree in June, 2025.
                </p>
                <p>
                  I've been doing research at the intersection of Computer Vision and Graphics, working closely with <a href="https://www.xzhou.me/">Prof. Xiaowei Zhou</a> and <a href="https://pengsida.net/">Prof. Sida Peng</a>.
                  I also spent a lovely summer at Stanford as a research intern, working with <a href="https://jiajunwu.com/">Prof. Jiajun Wu</a>, <a href="https://elliottwu.com/">Prof. Elliott Wu</a> and <a href="https://chen-geng.com/">Chen Geng</a>.
                </p>
                <p>
                  I produce music under both aliases <a href="http://m.kugou.com/singer/985501">AlexHe</a> and <a href="https://open.spotify.com/artist/1eaRqAFMkHloas4Gm5jBpJ?si=ZBr42w6mSLm-SUrGp0zDmA/">Elykz</a>, experimenting among the genres of House, Hip-hop and New-age. My original music has gathered over 2 million streams across platforms.
                </p>
                <p style="text-align:center">
                  <a href="mailto:alexhe2000@zju.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/Guangzhao_He_Resume.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=MpNYXowAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/AlexHe00880585">X</a> &nbsp;/&nbsp;
                  <a href="https://github.com/GuangzhaoHe">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/AlexHe.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/AlexHe.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>News</h2>
                  <ul>
                    <li>[2025.02] Our work <b>CANOR</b> is accepted to <b>CVPR 2025</b>. See you in Nashville!</li>
                    <li>[2024.06] I'll be joining <b>Stanford Vision and Learning Lab</b> supervised by <b><a href="https://jiajunwu.com/">Prof. Jiajun Wu</a></b> and <b><a href="https://elliottwu.com/">Prof. Shangzhe Wu</a></b>.</li>
                    <li>[2024.01] Our work <b>4K4D</b> is accepted to <b>CVPR 2024</b>.</li>
                    <li>[2023.07] Our work <b>EasyVolcap</b> is accepted to <b>SIGGRAPH Asia 2023 TC</b>.</li>
                  </ul>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                  <p>
                    My research interests lie at the intersection of <b>Vision</b> and <b>Graphics</b>, particularly in the <b>representation</b> and <b>understanding</b> of <b>dynamic 3D scenes</b>, with the goal of enabling machines to perceive the dynamic and diverse world as humans do.
                  </p>
              </td>
            </tr>
          </tbody></table>

          <!--canor-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout=" canor_stop()" onmouseover="canor_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='canor_image'>
                    <div class="rounded">
                      <video  width=100% muted autoplay loop>
                        <source src="images/canor.png">our browser does not support the video tag.
                      </video>
                    </div>
                  </div>

                  <div class="rounded">
                    <img src='images/canor.png' width=100%>
                  </div>
                </div>
                <script type="text/javascript">
                  function fourk4d_start() {
                    document.getElementById('canor_image').style.opacity = "1";
                  }

                  function fourk4d_stop() {
                    document.getElementById('canor_image').style.opacity = "0";
                  }
                  fourk4d_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <span class="papertitle">Category-Agnostic Neural Object Rigging</span>

                <br>
                <strong>Guangzhao He</strong>,
                <a href="https://chen-geng.com/">Chen Geng</a>,
                <a href="https://elliottwu.com/">Shangzhe Wu</a>,
                <a href="https://jiajunwu.com/">Jiajun Wu</a>
                <br>
                <em>CVPR</em>, 2025
                <br>
                <!-- <a href="https://zju3dv.github.io/4k4d/">project page</a>
                /
                <a href="https://arxiv.org/abs/2310.11448">arXiv</a> -->
                <p></p>
                <p>
                  A feed-forward representation that encodes deformable 4D objects into a sparse set of spatially-grounded blobs to disentangle pose and instance information, enabling intuitive pose manipulation while preserving rich instance-specific information. 
                </p>
              </td>
            </tr>
          </tbody></table>  

          <!--supergraph-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout=" supergraph_stop()" onmouseover="supergraph_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='supergraph_image'>
                    <div class="rounded">
                      <video  width=100% muted autoplay loop>
                        <source src="images/SuperGraph.png">our browser does not support the video tag.
                      </video>
                    </div>
                  </div>

                  <div class="rounded">
                    <img src='images/SuperGraph.png' width=100%>
                  </div>
                </div>
                <script type="text/javascript">
                  function fourk4d_start() {
                    document.getElementById('supergraph_image').style.opacity = "1";
                  }

                  function fourk4d_stop() {
                    document.getElementById('supergraph_image').style.opacity = "0";
                  }
                  fourk4d_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://zju3dv.github.io/4k4d/">
                  <span class="papertitle">SuperGraph: Generalizable Deformation Graph Estimation for Sequential Non-rigid Registration</span>
                </a> -->
                <!-- <p> -->
                <!-- </p> -->
                <span class="papertitle">SuperGraph: Generalizable Deformation Graph Estimation for Sequential Non-rigid Registration</span>

                <br>
                <strong>Guangzhao He</strong>,
                <a href="https://henry123-boy.github.io/">Yuxi Xiao</a>,
                <a href="https://pengsida.net/">Sida Peng</a>,
                <a href="https://zhenx.me/">Zhen Xu</a>,
                <a href="https://xzhou.me/">Xiaowei Zhou</a>
                <br>
                <em>Under Review</em>, 2024
                <br>
                <!-- <a href="https://zju3dv.github.io/4k4d/">project page</a>
                /
                <a href="https://arxiv.org/abs/2310.11448">arXiv</a> -->
                <p></p>
                <p>
                  A feed-forward pipeline that registers any object template onto a sequence of non-rigidly deforming point clouds, with 4.6x faster inference speed and 2x better accuracy than previous SOTA. 
                </p>
              </td>
            </tr>
          </tbody></table>  

          <!--4k4d-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout=" fourk4d_stop()" onmouseover="fourk4d_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='fourk4d_image'>
                    <div class="rounded">
                      <video  width=100% muted autoplay loop>
                        <source src="images/4K4D.mov" type="video/mp4">our browser does not support the video tag.
                      </video>
                    </div>
                  </div>

                  <div class="rounded">
                    <img src='images/4K4D.png' width=100%>
                  </div>
                </div>
                <script type="text/javascript">
                  function fourk4d_start() {
                    document.getElementById('fourk4d_image').style.opacity = "1";
                  }

                  function fourk4d_stop() {
                    document.getElementById('fourk4d_image').style.opacity = "0";
                  }
                  fourk4d_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <b> -->
                  <span class="papertitle">4K4D: Real-Time 4D View Synthesis at 4K Resolution</span>
                <!-- </b> -->
                <br>
                <a href="https://zhenx.me/">Zhen Xu</a>,
                <a href="https://pengsida.net/">Sida Peng</a>,
                <a href="https://haotongl.github.io/">Haotong Lin</a>,
                <strong>Guangzhao He</strong>,
                <a href="https://jiamingsun.ml/">Jiaming Sun</a>,
                <a href="https://shenyujun.github.io/">Yujun Shen</a>,
                <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,
                <a href="https://xzhou.me/">Xiaowei Zhou</a>
                <br>
                <em>CVPR</em>, 2024
                <br>
                <a href="https://zju3dv.github.io/4k4d/">project page</a>
                /
                <a href="https://arxiv.org/abs/2310.11448">arXiv</a>
                <p></p>
                <p>
                  A novel point-based 4D representation reconstructed with multi-view videos, which can be rendered at 4k 200+ FPS with state-of-the-art quality on a single RTX 4090.
                </p>
              </td>
            </tr>
          </tbody></table>  

          <!--easyvolcap-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout=" evc_stop()" onmouseover="evc_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='evc_image'>
                    <div class="rounded">
                      <video  width=100% muted autoplay loop>
                        <source src="images/EasyVolcap.mov" type="video/mp4">our browser does not support the video tag.
                      </video>
                    </div>
                  </div>
                  <div class="rounded">
                    <img src='images/EasyVolcap.png' width=100%>
                  </div>
                </div>
                <script type="text/javascript">
                  function evc_start() {
                    document.getElementById('evc_image').style.opacity = "1";
                  }

                  function evc_stop() {
                    document.getElementById('evc_image').style.opacity = "0";
                  }
                  evc_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://github.com/zju3dv/EasyVolcap"> -->
                <span class="papertitle">EasyVolcap: Accelerating Neural Volumetric Video Research</span>
                <!-- </a> -->
                <br>
                <a href="https://zhenx.me/">Zhen Xu</a>,
                <a href="https://github.com/xbillowy">Tao Xie</a>,
                <a href="https://pengsida.net/">Sida Peng</a>,
                <a href="https://haotongl.github.io/">Haotong Lin</a>,
                <a href="https://chingswy.github.io/">Qing Shuai</a>,
                <a href="https://zh1yu4nyu.github.io/">Zhiyuan Yu</a>,
                <strong>Guangzhao He</strong>,
                <a href="https://jiamingsun.ml/">Jiaming Sun</a>,
                <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,
                <a href="https://xzhou.me/">Xiaowei Zhou</a>
                <br>
                <em>SIGGRAPH Asia TC</em>, 2023
                <br>
                <a href="https://github.com/zju3dv/EasyVolcap/">github</a>
                /
                <a href="https://arxiv.org/abs/2312.06575">arXiv</a>
                <p></p>
                <p>
                  A Python & PyTorch library for accelerating volumetric video research, particularly in the area of neural dynamic scene representation, reconstruction, and rendering.
                  <!-- Given multi-view video input, EasyVolcap streamlines the process of data preprocessing, 4D reconstruction, and rendering of dynamic scenes. -->
                </p>
              </td>
            </tr>
          </tbody></table>  

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template by <a href="https://jonbarron.info/">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>

        </td>
      </tr>
    </table>
  </body>
</html>
